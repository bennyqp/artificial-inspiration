{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_image-generation_SinGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bennyqp/artificial-inspiration/blob/main/Image%20Generation/ai_image_generation_SinGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oo6DvqDiB9C9"
      },
      "source": [
        "#SinGAN\n",
        "_\n",
        "\n",
        "##This is a notebook from Derrick Schulz\n",
        "This notebook is completely and with no changes copied from Derrick Schulz\n",
        "\n",
        "(https://github.com/dvschultz)\n",
        "\n",
        "You can find the original here: \n",
        "\n",
        "https://github.com/dvschultz/ai/blob/master/SinGAN.ipynb\n",
        "\n",
        "_\n",
        "\n",
        "SinGAN is a ML library that allows you to do a lot of different things with one image as your dataset. As we’ve previously discussed usually you need a ton of images to be able to do anything in ML, so SinGAN needing only one image is a huge change.\n",
        "\n",
        "It is, however, important to keep in mind what its outputs are. SinGAN, to me, is most like Photoshop’s Context Aware tools. It allows you to manipulate the single image in interesting ways, but in the end is only going to return you that same image, slightly modified. SinGAN is a bit of a Swiss Army Knife and that makes it pretty cool in a world of single-use ML tools.\n",
        "\n",
        "Let’s take a look."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml04N83FROe-"
      },
      "source": [
        "##Set up our Runtime\n",
        "Colab needs to know we need to use a GPU-powered machine in order to do style transfers. At the top of this page, click on the `Runtime` tab, then select `Change runtime type`. In the modal that pops up, select `GPU` under the `Hardware accelerator` options."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcZrYaiYdZM5"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tatkCDnBqCH"
      },
      "source": [
        "## Set up SinGAN\n",
        "Let’s install the SinGAN repo and install all the dependencies needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx1w_rUCAUNB"
      },
      "source": [
        "!git clone https://github.com/dvschultz/SinGAN\n",
        "!pip install torch==1.4.0 torchvision==0.5.0\n",
        "%cd /content/SinGAN/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzHCfXOWCxds"
      },
      "source": [
        "We now have SinGAN installed on CoLab. Here are some relevant links to understand how to use the library:\n",
        "\n",
        "*   [SinGAN Github repo](https://github.com/tamarott/SinGAN)\n",
        "*   [ArXiv paper](https://arxiv.org/pdf/1905.01164.pdf)\n",
        "* [Supplementary Materials paper](https://tomer.net.technion.ac.il/files/2019/09/SingleImageGan_SM.pdf)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMvS1d2mDxqA"
      },
      "source": [
        "##Training your image\n",
        "In order to use SinGAN, we need to train the model on our image. In my experience this usually takes an hour or so to train a 250px image.\n",
        "\n",
        "The `main_train.py` script takes one required argument, `--input_name`. To use with a custom image, upload an image to the `Input/Images` folder and then pass its name and file extension to the argument. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doXwNrKBD4V8"
      },
      "source": [
        "!python main_train.py --input_name colusseum.png --max_size 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ISneFwF9Lfd"
      },
      "source": [
        "##Generating Random Samples\n",
        "By default, once training is completed 50 samples are generated. That means you don’t need to run the next line of code, unless you want to change some of the default options. \n",
        "\n",
        "Note: If you do run the next line of code, you’ll need to delete the folder of output images that were created during training. Otherwise you will get an error.\n",
        "\n",
        "###Sample Options\n",
        "\n",
        "####Number of Images\n",
        "`--num_samples` (note: this only works in my version of the library)\n",
        "\n",
        "You can pass in a number to generate any number of images. By default it generates 50. I recommend using this when running the `main_train.py` script otherwise you’ll need to delete the output folder and re-run it.\n",
        "\n",
        "####Generator scale\n",
        "`--gen_start_scale` (pass is a number, usually between 0–3)\n",
        "\n",
        "I don’t want to dig into this too deeply, so I’ll just say the generator scale relates to how \"realistic\" the new images look. If you use `0` you will get images that differ drastically from your original image. If you use `2` or `3` the differences will be very subtle. Anything above these numbers will give you almost no changes.\n",
        "\n",
        "####Mode\n",
        "`--mode`\n",
        "There are two. While the default `random_samples` generates images of the same size as your training image, `random_samples_arbitrary_sizes` changes the size of your canvas. It’s not a scaled up image, however, its more like it makes the canvas larger and tries to fill the space added with a similar texture.\n",
        "\n",
        "####Scale of canvas\n",
        "`--scale_h` (pass it a floating number)\n",
        "\n",
        "`--scale_v` \n",
        "\n",
        "For use with `random_samples_arbitrary_sizes`, this allows you to define how much larger (or smaller) the canvas should be. you should pass it a floating value that scales each dimension up or down (`1.0` is the same size, `2.0` is twice as large, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9GXUNGUGnDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c5b43ae-f83b-48cd-8806-bf3e739cfd41"
      },
      "source": [
        "# example using the default random_samples mode\n",
        "!python random_samples.py --input_name colusseum.png --mode random_samples --gen_start_scale 1 --num_samples 10 --max_size 256"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  2542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aERY946FXxcj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "846c3c38-29ee-4055-bf89-5bb25d771489"
      },
      "source": [
        "# example using the random_samples_arbitrary_sizes mode\n",
        "# can only run at --gen_start_scale 0 (https://github.com/tamarott/SinGAN/issues/61)\n",
        "!python random_samples.py --input_name colusseum.png --mode random_samples_arbitrary_sizes --scale_h 2.0 --scale_v 1.0 --gen_start_scale 0 --num_samples 10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Seed:  756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFTvgNUigrE-"
      },
      "source": [
        "##Generating Animations\n",
        "SinGAN can generate an animation from the single image. It essentially create a noisy peturbation on the image causing it to animate.\n",
        "\n",
        "Unfortunately, this requires another training session on the image. It should take the same amount of time as your previous training.\n",
        "\n",
        "`--min_size` and `--max_size` can be used here as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXHv8U14ZZ3q"
      },
      "source": [
        "!python animation.py --input_name colusseum.png --max_size 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJbh5OP92KMI"
      },
      "source": [
        "You can play the video in Colab by pointing the path to the following function (you may need to update the width and height arguments as well):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PluKyb_V0yvH"
      },
      "source": [
        "def show_local_mp4_video(file_name, width=640, height=480):\n",
        "  import io\n",
        "  import base64\n",
        "  from IPython.display import HTML\n",
        "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
        "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
        "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
        "                      </video>'''.format(width, height, video_encoded.decode('ascii')))\n",
        "\n",
        "show_local_mp4_video('/content/SinGAN/Output/Animation/colusseum/start_scale=2/alpha=0.100000_beta=0.800000.mp4', width=256, height=192)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnl05Rosz9IV"
      },
      "source": [
        "###Animation Options\n",
        "\n",
        "####Output type\n",
        "`--output_type`\n",
        "\n",
        "This allows you to output either `video` or `gif`. The default is `video`.\n",
        "\n",
        "`--num_frames`\n",
        "\n",
        "This determines the length of your animation. the default is `100` frames (10fps, so 10 seconds)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sdmxkGW7GjA"
      },
      "source": [
        "!python animation.py --input_name colusseum.png --max_size 256 --output_type gif --num_frames 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNtL1p3TP-vm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}