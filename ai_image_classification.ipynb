{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai_image_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bennyqp/artificial-inspiration/blob/main/ai_image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT045ULItiH_"
      },
      "source": [
        "#Image classification "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvY0XO3ytk2y"
      },
      "source": [
        "This notebook was created for the project [\"Artificial Inspiration\"](https://github.com/bennyqp/artificial-inspiration). \n",
        "\n",
        "It contains different techniques of image classification which have been collected from different sources in order to classify an image according to certain parameters as comprehensively as possible. \n",
        "\n",
        "All the results of the classification are then saved in a csv file, which is used in the rest of the project. The classified images are distributed in three-dimensional space based on the results in a Unity application and can then be filtered and clustered. \n",
        "\n",
        "All sources of the different techniques are mentioned in the course of the notebook. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bpdY2fJc7Bj"
      },
      "source": [
        "#Image Embedding by Jared Winick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1YRGN7ivw3W"
      },
      "source": [
        "The image embedding used here is by [Jared Winick](https://github.com/jaredwinick). It uses a fork of his [img2vec-keras module](https://github.com/jaredwinick/img2vec-keras) which is used to assign vectors to the images. The corresponding part of this notebook was taken from an [example notebook by Jared Winick](https://colab.research.google.com/drive/14OvmH6KvoQJ41jb6QRL3FgwI61vq-UAJ). \n",
        "\n",
        "https://github.com/jaredwinick/img2vec-keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA6PzU_ckYnB"
      },
      "source": [
        "!pip install git+git://github.com/bennyqp/img2vec-keras.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L5UTPU7khqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf861450-8d52-4a6f-b9b3-880dbabf9cd0"
      },
      "source": [
        "from img2vec_keras import Img2Vec\n",
        "\n",
        "from IPython.display import Image, display, Javascript\n",
        "\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "\n",
        "import cv2\n",
        "\n",
        "import imutils\n",
        "from base64 import b64decode\n",
        "\n",
        "\n",
        "img2vec = Img2Vec()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WJ0bU-c9z7a"
      },
      "source": [
        "def getListOfFiles(dirName):\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        # If entry is a directory then get the list of files in this directory \n",
        "        if os.path.isdir(fullPath):\n",
        "          if not entry.startswith(\".\"):\n",
        "            allFiles = allFiles + getListOfFiles(fullPath)\n",
        "        else:\n",
        "            allFiles.append(fullPath)\n",
        "                \n",
        "    return allFiles"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmDm_NtaEfbI"
      },
      "source": [
        "#Import Images from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh3G2z6SE7ya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "874fdd34-9b8a-4f5d-9eda-21678d1cf1b1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbdaxWa01eE0"
      },
      "source": [
        "####Set the input folder and the name for the output folder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJXekf5Qx4u2"
      },
      "source": [
        "The input path is where the images are currently located. \n",
        "\n",
        "The output name is the name of the folder where the final images should be located.\n",
        "\n",
        "The baseFolder is the folder where the output folder will be located. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-nTwnY7ASY"
      },
      "source": [
        "inputPath = \"/content/drive/MyDrive/input\"\n",
        "outputName = \"finalImages\"\n",
        "baseFolder = \"/content/drive/MyDrive/imageClassification\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qm6icFVv0bq"
      },
      "source": [
        "# 1. Get the Google Drive image ID and scale the images to a smaller size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRa7SEWlyzJU"
      },
      "source": [
        "For the project we need the Google Drive ID to be able to access specific images later.\n",
        "\n",
        "Also, we don't need the images in their original resolution. For the Unity application a smaller resolution is sufficient. In addition, the image classification is drastically accelerated. \n",
        "\n",
        "So the ID of the original images is saved, then the images are scaled and saved in a smaller format in a new folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-Gbb6BIzapq"
      },
      "source": [
        "#Set the reduced image size\n",
        "newImgWidth = 256\n",
        "newImgHeight = 256"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_C3gFP8HEd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48f8f834-f4c2-4fec-8429-8d7ec06d6a20"
      },
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from PIL import Image\n",
        "!apt-get install -qq xattr\n",
        "\n",
        "\n",
        "outputPath = os.path.join(baseFolder, outputName)\n",
        "if os.path.exists(outputPath) == False:\n",
        "  os.mkdir(outputPath)\n",
        "if os.path.exists(outputName) == False:\n",
        "  os.mkdir(outputName)\n",
        "\n",
        "image_paths = []\n",
        "dataDirs = getListOfFiles(inputPath)\n",
        "print(\"\")\n",
        "print(\"Adding \" + str(len(dataDirs)) + \" Images\")\n",
        "\n",
        "\n",
        "#Make a small version of each image and create an array with the ID of the original files\n",
        "originalImageIDs = []\n",
        "\n",
        "counter = 0\n",
        "for fileName in dataDirs:\n",
        "  \n",
        "  #Determine path of the original image and name of the original image\n",
        "  currentFilePath = fileName\n",
        "  fname = os.path.basename(fileName)\n",
        "\n",
        "  #Get Id of the original image and add it to the array\n",
        "  currentFileId = !xattr -p 'user.drive.id' $currentFilePath\n",
        "  originalImageIDs.append(currentFileId[0])\n",
        "\n",
        "  smallImgPath = os.path.join(outputPath, fname)\n",
        "  smallImgColabPath = os.path.join(outputName, fname)\n",
        "\n",
        "  #Resize \n",
        "  im = Image.open(currentFilePath)\n",
        "  im_resized = im.resize((newImgWidth, newImgHeight), Image.ANTIALIAS)\n",
        "  im_resized.save(smallImgPath, quality=95)\n",
        "  im_resized.save(smallImgColabPath, quality=95)\n",
        "\n",
        "  #Add Colab Path\n",
        "  image_paths.append(smallImgColabPath)\n",
        "\n",
        "  #Loop Information\n",
        "  if (counter % 10 == 0):\n",
        "    print(str(counter) + \" / \" + str(len(dataDirs)))\n",
        "  counter = counter + 1\n",
        "\n",
        "print(\"done.\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Adding 68 Images\n",
            "0 / 68\n",
            "10 / 68\n",
            "20 / 68\n",
            "30 / 68\n",
            "40 / 68\n",
            "50 / 68\n",
            "60 / 68\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oinT0m31BKY"
      },
      "source": [
        "#2. Compute image vectors "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMM5IDG41n4f"
      },
      "source": [
        "###2.1 image embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWP1dBYw1JcP"
      },
      "source": [
        "Now we will perform the image embedding. As mentioned before the image embedding used here is by [Jared Winick](https://github.com/jaredwinick):\n",
        "\n",
        "https://github.com/jaredwinick/img2vec-keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFt2u6x7koyL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b25e09-a3fc-4796-dd1b-b13ea9bae051"
      },
      "source": [
        "image_vectors = {}\n",
        "counter = 0\n",
        "for image_path in image_paths:\n",
        "  vector = img2vec.get_vec(image_path)\n",
        "  image_vectors[image_path] = vector\n",
        "\n",
        "  counter = counter + 1;\n",
        "  if (counter % 10 == 0):\n",
        "    print(\"Analyzed \" + str(counter) + \" of \" + str(len(image_paths)) + \" Images.\")\n",
        "print(\"done.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzed 10 of 68 Images.\n",
            "Analyzed 20 of 68 Images.\n",
            "Analyzed 30 of 68 Images.\n",
            "Analyzed 40 of 68 Images.\n",
            "Analyzed 50 of 68 Images.\n",
            "Analyzed 60 of 68 Images.\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62Y-pWXnv6dq"
      },
      "source": [
        "###2.2 Dimension reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU8sFHbT2EjK"
      },
      "source": [
        "Since we only need three-dimensional vectors for the project in order to distribute the images in three-dimensional space, we perform a dimensional reduction. For this we use the T-SNE and the PCA algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVW9FntQ0mRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1820f86-ad42-400d-bde9-bd26a731a842"
      },
      "source": [
        "X = np.stack(list(image_vectors.values()))\n",
        "\n",
        "pca_50 = PCA(n_components=50)\n",
        "pca_result_50 = pca_50.fit_transform(X)\n",
        "print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50.explained_variance_ratio_)))\n",
        "print(np.shape(pca_result_50))\n",
        "\n",
        "    \n",
        "tsne = TSNE(n_components=3, verbose=1, n_iter=3000)\n",
        "tsne_result = tsne.fit_transform(pca_result_50)\n",
        "\n",
        "tsne_result_scaled = StandardScaler().fit_transform(tsne_result)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cumulative explained variation for 50 principal components: 0.9419956207275391\n",
            "(68, 50)\n",
            "[t-SNE] Computing 67 nearest neighbors...\n",
            "[t-SNE] Indexed 68 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 68 samples in 0.005s...\n",
            "[t-SNE] Computed conditional probabilities for sample 68 / 68\n",
            "[t-SNE] Mean sigma: 14.497902\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 125.099579\n",
            "[t-SNE] KL divergence after 3000 iterations: 1.006268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdp25h762p5o"
      },
      "source": [
        "We can check the shape of the result to see if we did everything right:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55UBbl48LlGe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e122fb93-3a40-449f-f929-ed5c87860fba"
      },
      "source": [
        "np.shape(tsne_result_scaled)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKVlWLJO7AaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "da8b689a-7111-4c67-afe7-02a57ddec868"
      },
      "source": [
        "plt.scatter(tsne_result_scaled[:,0], tsne_result_scaled[:,1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fe76ea11890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQvuSb8bAkgv"
      },
      "source": [
        "#3. Analyze image composition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLs1BAl64ssO"
      },
      "source": [
        "Now we would like to analyze the image composition. To do this, we'll use the same process of image embedding again. However, we change all images into black and white images before, so that the algorithm really only concentrates on the structures in the image and the color no longer plays a role. \n",
        "\n",
        "Then we perform another dimension reduction, but this time we reduce to a single dimension. This way we get a scale that indicates the degree of image composition of the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTTDKn9rAyqL",
        "outputId": "19739000-80a7-42ef-e0ef-d6da56fe3efb"
      },
      "source": [
        "import shutil\n",
        "\n",
        "image_style_vectors = []\n",
        "\n",
        "counter = 0\n",
        "stepFolderName = \"styleStep\"\n",
        "if not os.path.exists(stepFolderName): \n",
        "  os.mkdir(stepFolderName)\n",
        "\n",
        "for image_path in image_paths:\n",
        "  \n",
        "  #Create black and white Version of the image \n",
        "  im = Image.open(image_path).convert('LA')\n",
        "  \n",
        "  im.save(os.path.join(stepFolderName, \"sytleStep.png\"), quality=95)\n",
        "\n",
        "  #Get Vector\n",
        "  vector = img2vec.get_vec(os.path.join(stepFolderName, \"sytleStep.png\"))\n",
        "  image_style_vectors.append(vector)\n",
        "  \n",
        "  counter += 1\n",
        "\n",
        "  if (counter % 10 == 0):\n",
        "    print(\"Analyzed \" + str(counter) + \" of \" + str(len(image_paths)) + \" Images.\")\n",
        "    \n",
        "shutil.rmtree(stepFolderName)\n",
        "\n",
        "X2 = np.stack(list(image_style_vectors))\n",
        "\n",
        "pca_50_2 = PCA(n_components=50)\n",
        "pca_result_50_2 = pca_50_2.fit_transform(X2)\n",
        "print('Cumulative explained variation for 50 principal components: {}'.format(np.sum(pca_50_2.explained_variance_ratio_)))\n",
        "print(np.shape(pca_result_50_2))\n",
        "\n",
        "    \n",
        "tsne2 = TSNE(n_components=1, verbose=1, n_iter=4500)\n",
        "tsne_result_2 = tsne2.fit_transform(pca_result_50_2)\n",
        "style_result_unscaled = StandardScaler().fit_transform(tsne_result_2)\n",
        "\n",
        "min = 10\n",
        "max = -10\n",
        "for unscaled in style_result_unscaled:\n",
        "  unscaledNum = unscaled[0]\n",
        "  if unscaledNum < min:\n",
        "    min = unscaledNum\n",
        "  if unscaledNum > max:\n",
        "    max = unscaledNum\n",
        "\n",
        "image_styles = []\n",
        "for unscaled in style_result_unscaled:\n",
        "  styleValue = (((unscaled[0] - min) * (100 - 0)) / (max - min)) + 0\n",
        "  image_styles.append(\"%.4f\" % styleValue)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analyzed 10 of 68 Images.\n",
            "Analyzed 20 of 68 Images.\n",
            "Analyzed 30 of 68 Images.\n",
            "Analyzed 40 of 68 Images.\n",
            "Analyzed 50 of 68 Images.\n",
            "Analyzed 60 of 68 Images.\n",
            "Cumulative explained variation for 50 principal components: 0.9454770088195801\n",
            "(68, 50)\n",
            "[t-SNE] Computing 67 nearest neighbors...\n",
            "[t-SNE] Indexed 68 samples in 0.001s...\n",
            "[t-SNE] Computed neighbors for 68 samples in 0.002s...\n",
            "[t-SNE] Computed conditional probabilities for sample 68 / 68\n",
            "[t-SNE] Mean sigma: 13.236779\n",
            "[t-SNE] KL divergence after 250 iterations with early exaggeration: 69.615753\n",
            "[t-SNE] KL divergence after 650 iterations: 6.220466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRKBzds8kiZ8"
      },
      "source": [
        "#4. Analyze image colors "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HWnpym75sT6"
      },
      "source": [
        "Next, we want to analyze the colors of the images so that we can later filter or sort the images by color. For this we use the k-Means algorithm. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ4fd8EtkejB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374be742-5667-408b-ee37-da142fb50f15"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Input \n",
        "colorNumber = 5\n",
        "\n",
        "##Lets Go\n",
        "imageColors = []\n",
        "colorPercent = []\n",
        "\n",
        "colorStepFolderName = \"colorClusterStep\"\n",
        "if not os.path.exists(colorStepFolderName): \n",
        "  os.mkdir(colorStepFolderName)\n",
        "\n",
        "loopCounter = 0\n",
        "loopLength = len(image_paths)\n",
        "for imagePath in image_paths:\n",
        "  #Resize image\n",
        "  im = Image.open(imagePath)\n",
        "  im_resized = im.resize((60, 60), Image.ANTIALIAS)\n",
        "  im_resized.save(os.path.join(colorStepFolderName, \"colorClustStep.png\"), quality=95)\n",
        "\n",
        "  #read Image\n",
        "  img=cv2.imread(os.path.join(colorStepFolderName, \"colorClustStep.png\"))\n",
        "  #Convert Colors from BGR to RGB \n",
        "  img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "  #Reshape Image-Array\n",
        "  img=img.reshape((img.shape[1]*img.shape[0],3))\n",
        "  #Find Color-Clusters with K-Means\n",
        "  kmeans=KMeans(n_clusters=colorNumber)\n",
        "  s=kmeans.fit(img)\n",
        "  #Find Labels for Clusters\n",
        "  labels=kmeans.labels_\n",
        "  labels=list(labels)\n",
        "  #Find Cluster Centers\n",
        "  centroid=kmeans.cluster_centers_\n",
        "  #Calculate Percentage of Clusters\n",
        "  percent=[]\n",
        "  for i in range(len(centroid)):\n",
        "    j=labels.count(i)\n",
        "    j=j/(len(labels))\n",
        "    percent.append(j)\n",
        "  imageColors.append(centroid)\n",
        "  colorPercent.append(percent)\n",
        "\n",
        "  loopCounter += 1\n",
        "  if (loopCounter % 10 == 0):\n",
        "    print(str(loopCounter) + \" / \" + str(loopLength))\n",
        "shutil.rmtree(colorStepFolderName)\n",
        "print(\"done.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 / 68\n",
            "20 / 68\n",
            "30 / 68\n",
            "40 / 68\n",
            "50 / 68\n",
            "60 / 68\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKdS0O2r6N-E"
      },
      "source": [
        "The color analysis is now ready. But we still have to prepare the results a bit to write them cleanly into the CSV file later. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTfpzj_9UUKM",
        "outputId": "c32cc1eb-59aa-441e-c9d0-2422f7453dff"
      },
      "source": [
        "arraycolorPercent = np.array(colorPercent)\n",
        "arraycolorPercent = np.around(arraycolorPercent, 2)\n",
        "stringColorPercent = []\n",
        "for i in range(len(arraycolorPercent)):\n",
        "  thisStr = ', '.join(map(str,arraycolorPercent[i]))\n",
        "  stringColorPercent.append(thisStr)\n",
        "\n",
        "arrayImgColors = np.array(imageColors)\n",
        "arrayImgColors = np.round(arrayImgColors)\n",
        "arrayImgColors = arrayImgColors.astype(int)\n",
        "stringImgColors = []\n",
        "for i in range(len(arrayImgColors)):\n",
        "  thisStr = \"\"\n",
        "  for e in range(len(arrayImgColors[i])):\n",
        "    thisStr = thisStr + ', '.join(map(str,arrayImgColors[i][e]))\n",
        "    if e < len(arrayImgColors[i]) - 1:\n",
        "      thisStr = thisStr + \"|\"\n",
        "  stringImgColors.append(thisStr)\n",
        "print(\"Done.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbWb3xwae586"
      },
      "source": [
        "#5. Analyze abstractness "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUcw9Vlz7HZM"
      },
      "source": [
        "The last thing we want to do is to find out the level of abstractness of the images. Since the project \"Artificial Inspiration\" deals with portraits, we use a face detection model. \n",
        "\n",
        "Depending on the purpose, this approach might not make sense for you. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QWgobnD7_88"
      },
      "source": [
        "We use an opencv face recognition model for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hG6vx7kq8UPG",
        "outputId": "ef212813-7756-4374-da0d-8d1674ab8a06"
      },
      "source": [
        "#download the model\n",
        "!gdown --id 1-F0w6qs2RsMg1GafpgW3eImnviYHbnDx\n",
        "!gdown --id 1-Dx2aHuXqu3413lWJ36JHyH9vd9zheEd\n",
        "#open the model\n",
        "prototxt = 'deploy.prototxt'\n",
        "model = 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "net = cv2.dnn.readNetFromCaffe(prototxt, model)\n",
        "\n",
        "#Start the analysis\n",
        "abstractLevels = []\n",
        "counter = 0\n",
        "for imagePath in image_paths:\n",
        "  thisImagePath = \"/\" + os.path.join(\"content\", imagePath)\n",
        "  image = cv2.imread(thisImagePath)\n",
        "  image = imutils.resize(image, width=400)\n",
        "  (h, w) = image.shape[:2]\n",
        "  blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
        "  net.setInput(blob)\n",
        "  detections = net.forward()\n",
        "  prevBoxSize = 0\n",
        "  mainDetectionNum = 0\n",
        "  for i in range(0, detections.shape[2]):\n",
        "    prob = detections[0, 0, i, 2]\n",
        "    box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "    boxSize = (endX - startX) * (endY - startY)\n",
        "    if boxSize > prevBoxSize:\n",
        "      mainDetectionNum = i\n",
        "      prevBoxSize = boxSize\n",
        "\n",
        "  abstractLevel = 1 - detections[0, 0, mainDetectionNum, 2]\n",
        "\n",
        "  if prevBoxSize < 40000:\n",
        "    abstractLevel += 0.1\n",
        "\n",
        "  abstractLevels.append(abstractLevel)\n",
        "  if (counter % 10 == 0):\n",
        "    print(str(counter) + \" / \" + str(len(image_paths)))\n",
        "  counter = counter + 1\n",
        "\n",
        "abstractLevels = np.around(abstractLevels, 2)\n",
        "\n",
        "#delete model again\n",
        "os.remove(\"deploy.prototxt\")\n",
        "os.remove(\"res10_300x300_ssd_iter_140000.caffemodel\")\n",
        "\n",
        "print(\"done.\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-F0w6qs2RsMg1GafpgW3eImnviYHbnDx\n",
            "To: /content/res10_300x300_ssd_iter_140000.caffemodel\n",
            "10.7MB [00:00, 106MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-Dx2aHuXqu3413lWJ36JHyH9vd9zheEd\n",
            "To: /content/deploy.prototxt\n",
            "100% 28.1k/28.1k [00:00<00:00, 50.1MB/s]\n",
            "0 / 68\n",
            "10 / 68\n",
            "20 / 68\n",
            "30 / 68\n",
            "40 / 68\n",
            "50 / 68\n",
            "60 / 68\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvKwyIABffcN"
      },
      "source": [
        "#6. Create CSV file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtbfszG4-Grz"
      },
      "source": [
        "Finally, we write all the analyzed data to a CSV file. \n",
        "\n",
        "We can later import this file into Unity together with the created images. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knkZqBfxgHw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e5d16c5-4596-47ec-8bd4-f22777537e46"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "new = \"images\" #Path under which the images will be located in the Unity application\n",
        "\n",
        "csv_name = os.path.join(baseFolder, outputName + \"-img2vec.csv\") #Name of the CSV file\n",
        "\n",
        "#File path is now prepared for Unity:\n",
        "old = outputName #old Path\n",
        "unity_paths = []\n",
        "for key in image_vectors.keys():\n",
        "  new_key = key.replace(old, new)\n",
        "  new_key = new_key.replace(\".png\", \"\")\n",
        "  unity_paths.append(new_key) \n",
        "\n",
        "#Create CSV file and write image vectors into it:\n",
        "with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"tsneX\", \"tsneY\", \"tsneZ\"])\n",
        "    writer.writerows(tsne_result_scaled)\n",
        "\n",
        "#Now open the CSV file with Pandas:\n",
        "df = pd.read_csv(csv_name)\n",
        "\n",
        "#Insert file paths of the images for Unity \n",
        "path_column = pd.DataFrame({'path': unity_paths})\n",
        "df = df.merge(path_column, left_index = True, right_index = True)\n",
        "\n",
        "#Reorder dataframe\n",
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]\n",
        "\n",
        "#Fill CSV with color data\n",
        "colors_column = pd.DataFrame({'colors': stringImgColors})\n",
        "df = df.merge(colors_column, left_index = True, right_index = True)\n",
        "\n",
        "#Fill CSV with color percentages\n",
        "colors_column = pd.DataFrame({'colorPercent': stringColorPercent})\n",
        "df = df.merge(colors_column, left_index = True, right_index = True)\n",
        "\n",
        "#Fill CSV with abstract level data\n",
        "colors_column = pd.DataFrame({'abstractLevel': abstractLevels})\n",
        "df = df.merge(colors_column, left_index = True, right_index = True)\n",
        "\n",
        "#Fill CSV with composition data\n",
        "colors_column = pd.DataFrame({'style': image_styles})\n",
        "df = df.merge(colors_column, left_index = True, right_index = True)\n",
        "\n",
        "#Fill CSV with Drive ID of original images\n",
        "colors_column = pd.DataFrame({'ID': originalImageIDs})\n",
        "df = df.merge(colors_column, left_index = True, right_index = True)\n",
        "\n",
        "#and save CSV\n",
        "df.to_csv(csv_name, index = False, sep = ';')\n",
        "\n",
        "print(\"All done now. Cool!\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All done now. Cool!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU-4Yf8_dEXE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}